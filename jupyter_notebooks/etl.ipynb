{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Food Price analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Objectives\n",
        "\n",
        "Create a single, analysis-ready dataset by:\n",
        "\n",
        "* Loading and cleaning the two raw CSVs from the Global Food Price Inflation 2024 Kaggle archive\n",
        "\n",
        "* Standardising column names, parsing dates, and coercing numeric fields\n",
        "\n",
        "* Harmonising key categorical fields (e.g., country, item)\n",
        "\n",
        "* Merging item-/series-level details with country-level context using reliable keys\n",
        "\n",
        "* Saving cleaned per-file outputs and a merged dataset for downstream analysis\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* data/WLD_RTFP_country_2023-10-02.csv\n",
        "\n",
        "* data/WLD_RTP_details_2023-10-02.csv\n",
        "\n",
        "* Python packages: pandas, numpy, os, re, pathlib\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* data/WLD_RTFP_country_2023-10-02_clean.csv\n",
        "\n",
        "* data/WLD_RTP_details_2023-10-02_clean.csv\n",
        "\n",
        "* data/food_price_merged_cleaned.csv\n",
        "\n",
        "* data/food_price_feature_engineered_clean.csv (final validated version)\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* Join strategy: left join from details → country using keys:\n",
        "\n",
        "1. [\"country\", \"date\", \"item\"]\n",
        "\n",
        "2. [\"country\", \"date\"]\n",
        "\n",
        "3. [\"country\"] (fallback)\n",
        "\n",
        "* date comes from end_date_observations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We assume this notebook sits in a subfolder (e.g., jupyter_notebooks/). We make the parent the working directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/aminaibrahim/Documents/vscode-projects/food-price-inflation-analysis/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Access the current directory\n",
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "# Make the parent directory current\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/aminaibrahim/Documents/vscode-projects/food-price-inflation-analysis'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Confirm new current directory\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "country_path = \"data/WLD_RTFP_country_2023-10-02.csv\"\n",
        "details_path = \"data/WLD_RTP_details_2023-10-02.csv\"\n",
        "\n",
        "country_df = pd.read_csv(country_path)\n",
        "details_df = pd.read_csv(details_path)\n",
        "\n",
        "# Parse end_date_observations as datetime (add this line here)\n",
        "details_df['end_date_observations'] = pd.to_datetime(details_df['end_date_observations'], format='%b %Y', errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defines reusable cleaning functions to:\n",
        "- Standardise column names\n",
        "- Tidy string values\n",
        "- Parse date columns\n",
        "- Convert numeric-looking strings to numbers\n",
        "- Remove nearly empty columns\n",
        "- Harmonise key categorical fields\n",
        "- Provide quick summary reports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Standardize column names: strip spaces, remove special characters, replace spaces with underscores, and lowercase\n",
        "def normalise_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    df.columns = (\n",
        "        df.columns\n",
        "          .str.strip()\n",
        "          .str.replace(r\"[^\\w\\s]\", \"\", regex=True)\n",
        "          .str.replace(r\"\\s+\", \"_\", regex=True)\n",
        "          .str.lower()\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# Clean string columns: strip leading/trailing spaces and collapse multiple spaces into one\n",
        "def tidy_strings(df: pd.DataFrame, cols) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            df[c] = (df[c].astype(str)\n",
        "                           .str.strip()\n",
        "                           .str.replace(r\"\\s+\", \" \", regex=True))\n",
        "    return df\n",
        "\n",
        "# Parse columns with names like 'date', 'month', 'year', or 'period' into datetime objects\n",
        "def parse_dates(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    # Specify formats for known date columns\n",
        "    date_formats = {\n",
        "        \"end_date_observations\": \"%b %Y\",\n",
        "        # Add more if needed\n",
        "    }\n",
        "    for c in df.columns:\n",
        "        if re.search(r\"(date|month|year|period)\", c):\n",
        "            fmt = date_formats.get(c)\n",
        "            try:\n",
        "                if fmt:\n",
        "                    df[c] = pd.to_datetime(df[c], format=fmt, errors=\"coerce\")\n",
        "                else:\n",
        "                    df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
        "            except Exception:\n",
        "                pass\n",
        "    return df\n",
        "\n",
        "# Convert columns that look numeric (even if stored as strings) to numeric dtype\n",
        "def coerce_numeric(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    for c in df.columns:\n",
        "        if df[c].dtype == object:\n",
        "            sample = df[c].dropna().astype(str).head(50)\n",
        "            looks_numeric = (\n",
        "                not sample.empty and\n",
        "                sample.str.replace(\",\",\"\", regex=False)\n",
        "                      .str.replace(\"%\",\"\", regex=False)\n",
        "                      .str.match(r\"^-?\\d+(\\.\\d+)?$\")\n",
        "                      .mean() > 0.6\n",
        "            )\n",
        "            if looks_numeric:\n",
        "                df[c] = (df[c].astype(str)\n",
        "                               .str.replace(\",\",\"\", regex=False)\n",
        "                               .str.replace(\"%\",\"\", regex=False)\n",
        "                               .str.strip())\n",
        "                df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "# Drop columns that are nearly empty (default: 98% or more missing values)\n",
        "def drop_nearly_empty(df: pd.DataFrame, thresh=0.98) -> pd.DataFrame:\n",
        "    na_ratio = df.isna().mean()\n",
        "    to_drop = na_ratio[na_ratio >= thresh].index.tolist()\n",
        "    return df.drop(columns=to_drop) if to_drop else df\n",
        "\n",
        "# Run all cleaning steps in sequence for a generic DataFrame\n",
        "def clean_generic(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    out = df.copy()\n",
        "    out = normalise_columns(out)\n",
        "    out = out.drop_duplicates()\n",
        "    # Identify likely categorical columns and clean them\n",
        "    cat_cols = [c for c in out.columns if out[c].dtype == object]\n",
        "    priority = [c for c in [\"country\",\"country_name\",\"item\",\"commodity\",\"product\",\"unit\",\"currency\",\"series\",\"market\"] if c in out.columns]\n",
        "    out = tidy_strings(out, list(dict.fromkeys(priority + cat_cols)))\n",
        "    for c in [\"country\",\"country_name\"]:\n",
        "        if c in out.columns:\n",
        "            out[c] = out[c].str.title()\n",
        "    out = parse_dates(out)\n",
        "    out = coerce_numeric(out)\n",
        "    out = drop_nearly_empty(out, thresh=0.98)\n",
        "    return out\n",
        "\n",
        "# Print a brief summary report of the DataFrame's shape, duplicate count, and top missing columns\n",
        "def brief_report(df: pd.DataFrame, name: str):\n",
        "    print(f\"{name}: shape={df.shape}, duplicates={df.duplicated().sum()}\")\n",
        "    miss = df.isna().sum()\n",
        "    if miss.any():\n",
        "        print(\"  top missing:\", miss.sort_values(ascending=False).head(5).to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defined reusable functions to standardise column names, clean string and numeric fields, parse dates, and drop nearly empty columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Applying Data Cleaning Functions\n",
        "\n",
        "Cleans both datasets using the utility functions, removes duplicates, standardises formats, and generates a brief report on shape, duplicates, and missing values for each file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['country', 'iso3', 'components', 'currency', 'start_date_observations',\n",
            "       'end_date_observations', 'number_of_markets_modeled',\n",
            "       'number_of_markets_covered', 'number_of_food_items',\n",
            "       'number_of_observations_food', 'number_of_observations_other',\n",
            "       'data_coverage_food', 'data_coverage_previous_12_months_food',\n",
            "       'total_food_price_increase_since_start_date',\n",
            "       'average_annualized_food_inflation', 'maximum_food_drawdown',\n",
            "       'average_annualized_food_volatility',\n",
            "       'average_monthly_food_price_correlation_between_markets',\n",
            "       'average_annual_food_price_correlation_between_markets',\n",
            "       'Rsquared_individual_food_items', 'Rsquared_individual_other_items',\n",
            "       'index_confidence_score', 'imputation_model'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(details_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0   2023-09-01\n",
            "1   2023-08-01\n",
            "2   2023-07-01\n",
            "3   2023-06-01\n",
            "4   2023-08-01\n",
            "Name: end_date_observations, dtype: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "print(details_df['end_date_observations'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Country (clean): shape=(4798, 8), duplicates=0\n",
            "  top missing: {'inflation': 364, 'open': 64, 'high': 64, 'low': 64, 'close': 64}\n",
            "Details (clean): shape=(25, 22), duplicates=0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/09/yd5kcn1539g31p80cnw4dmr80000gn/T/ipykernel_56340/1962588202.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
            "/var/folders/09/yd5kcn1539g31p80cnw4dmr80000gn/T/ipykernel_56340/1962588202.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
            "/var/folders/09/yd5kcn1539g31p80cnw4dmr80000gn/T/ipykernel_56340/1962588202.py:42: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n"
          ]
        }
      ],
      "source": [
        "# Clean both datasets using the generic cleaning function\n",
        "country_clean = clean_generic(country_df)\n",
        "details_clean = clean_generic(details_df)\n",
        "\n",
        "# Create unified date from end_date_observations\n",
        "for df in [country_clean, details_clean]:\n",
        "    if \"end_date_observations\" in df.columns:\n",
        "        df[\"date\"] = df[\"end_date_observations\"]\n",
        "    elif \"start_date_observations\" in df.columns:\n",
        "        df[\"date\"] = df[\"start_date_observations\"]\n",
        "\n",
        "# Print a summary report for each cleaned DataFrame\n",
        "brief_report(country_clean, \"Country (clean)\")\n",
        "brief_report(details_clean, \"Details (clean)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Applied the cleaning functions to both datasets, removed duplicates, and generated summary reports to check for missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 4 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Cleaned Data\n",
        "\n",
        "After cleaning, we save the processed DataFrames as new CSV files in the `data/` directory.  \n",
        "This ensures that the cleaned datasets are available for downstream analysis or sharing, without overwriting the original raw files.  \n",
        "The file names include `_clean` to indicate they have been processed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: data/WLD_RTFP_country_2023-10-02_clean.csv\n",
            "Saved: data/WLD_RTP_details_2023-10-02_clean.csv\n"
          ]
        }
      ],
      "source": [
        "# Save cleaned versions alongside the raw files in 'data/'\n",
        "country_out = \"data/WLD_RTFP_country_2023-10-02_clean.csv\"\n",
        "details_out = \"data/WLD_RTP_details_2023-10-02_clean.csv\"\n",
        "\n",
        "country_clean.to_csv(country_out, index=False)\n",
        "details_clean.to_csv(details_out, index=False)\n",
        "\n",
        "print(\"Saved:\", country_out)\n",
        "print(\"Saved:\", details_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion & Summary\n",
        "\n",
        "In this notebook, I have taken raw food price inflation data and transformed it into a clean, analysis-ready dataset through a series of structured ETL (Extract, Transform, Load) steps:\n",
        "\n",
        "- **Data Cleaning:** Loaded the raw CSV files, standardized column names, parsed dates, coerced numeric fields, and harmonized key categorical variables.\n",
        "- **Quality Assurance:** Checked for duplicates and missing values, ensuring the integrity of the cleaned data.\n",
        "- **Merging:** Combined country-level and item-level datasets using robust join keys, resolving duplicate key issues to prevent data inflation.\n",
        "- **Feature Engineering:** Created new variables such as time-based features, percentage changes, rolling averages, one-hot encodings, and missing value flags to enrich the dataset for analysis and modeling.\n",
        "- **Final Validation:** Performed comprehensive data quality checks and cleaned up any problematic columns\n",
        "\n",
        "This process ensures that the final dataset is tidy, consistent, and rich in features, making it suitable for exploratory data analysis, visualization, and predictive modeling. You can now confidently use `data/food_price_feature_engineered_clean.csv` for further insights and machine learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging on keys: ['country', 'date']\n",
            "Duplicate keys - Country: 0, Details: 0\n",
            "Merged shape: (25, 28)\n",
            "Missing matches: 0\n"
          ]
        }
      ],
      "source": [
        "# Prepare datasets for merging\n",
        "def add_country_key(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    if \"country\" not in df.columns and \"country_name\" in df.columns:\n",
        "        df[\"country\"] = df[\"country_name\"]\n",
        "    return df\n",
        "\n",
        "def ensure_date(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    df = df.copy()\n",
        "    if \"date\" not in df.columns:\n",
        "        for alt in [\"month\",\"period\",\"year\"]:\n",
        "            if alt in df.columns and pd.api.types.is_datetime64_any_dtype(df[alt]):\n",
        "                df[\"date\"] = df[alt]\n",
        "                break\n",
        "    return df\n",
        "\n",
        "# Prepare datasets\n",
        "country_keyed = ensure_date(add_country_key(country_clean))\n",
        "details_keyed = ensure_date(add_country_key(details_clean))\n",
        "\n",
        "# Select join keys automatically\n",
        "candidate_key_sets = [[\"country\",\"date\",\"item\"], [\"country\",\"date\"], [\"country\"]]\n",
        "chosen = None\n",
        "for keys in candidate_key_sets:\n",
        "    if all(k in country_keyed.columns for k in keys) and all(k in details_keyed.columns for k in keys):\n",
        "        chosen = keys\n",
        "        break\n",
        "\n",
        "if not chosen:\n",
        "    raise ValueError(\"No suitable join keys found.\")\n",
        "\n",
        "print(\"Merging on keys:\", chosen)\n",
        "\n",
        "# Check and resolve duplicate keys\n",
        "country_dups = country_keyed.duplicated(subset=chosen).sum()\n",
        "details_dups = details_keyed.duplicated(subset=chosen).sum()\n",
        "print(f\"Duplicate keys - Country: {country_dups}, Details: {details_dups}\")\n",
        "\n",
        "if country_dups > 0:\n",
        "    country_keyed = country_keyed.drop_duplicates(subset=chosen)\n",
        "    print(f\"Resolved {country_dups} duplicate keys in country dataset\")\n",
        "\n",
        "# Perform merge\n",
        "merged = pd.merge(\n",
        "    details_keyed,\n",
        "    country_keyed,\n",
        "    on=chosen,\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\", \"_country\")\n",
        ").drop_duplicates()\n",
        "\n",
        "print(f\"Merged shape: {merged.shape}\")\n",
        "print(f\"Missing matches: {merged['country'].isna().sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resolving Duplicate Keys Before Merging\n",
        "\n",
        "When I check for duplicate keys before merging, I see that there are 4773 duplicate key rows in my `country_keyed` DataFrame and 0 in `details_keyed`. This means that, for my chosen join keys, the country-level data is not unique. If I merge as-is, each row in `details_keyed` will join with all matching rows in `country_keyed`, which could inflate my merged dataset and introduce errors.\n",
        "\n",
        "Additionally, I see there are no missing values for the 'country' key in either DataFrame, so I don't need to worry about missing join keys.\n",
        "\n",
        "Now that I've identified duplicate keys in my `country_keyed` DataFrame, I need to resolve them before merging. This helps prevent data inflation and ensures the merged dataset is accurate.\n",
        "\n",
        "If the duplicate rows are exact matches, I can safely drop them. If they differ, I'll need to review and decide how to aggregate or select a representative row for each key."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Merged Cleaned File & Quick Quality Assurance\n",
        "\n",
        "Now that I've resolved duplicate keys and completed the merge, I will save the final cleaned dataset to disk.  \n",
        "I'll also run a quick quality assurance check by summarizing numeric columns and showing the most frequent values for key categorical columns.  \n",
        "This helps ensure the merged data is ready for downstream analysis and gives me a first look at the data distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved merged cleaned dataset: data/food_price_merged_cleaned.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>number_of_markets_modeled</th>\n",
              "      <td>25.0</td>\n",
              "      <td>56.4800</td>\n",
              "      <td>47.682212</td>\n",
              "      <td>9.00</td>\n",
              "      <td>24.00</td>\n",
              "      <td>42.00</td>\n",
              "      <td>79.00</td>\n",
              "      <td>228.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_markets_covered</th>\n",
              "      <td>25.0</td>\n",
              "      <td>56.4800</td>\n",
              "      <td>47.682212</td>\n",
              "      <td>9.00</td>\n",
              "      <td>24.00</td>\n",
              "      <td>42.00</td>\n",
              "      <td>79.00</td>\n",
              "      <td>228.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_of_food_items</th>\n",
              "      <td>25.0</td>\n",
              "      <td>9.3200</td>\n",
              "      <td>7.016172</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.00</td>\n",
              "      <td>7.00</td>\n",
              "      <td>11.00</td>\n",
              "      <td>26.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>data_coverage_food</th>\n",
              "      <td>25.0</td>\n",
              "      <td>35.3404</td>\n",
              "      <td>17.451470</td>\n",
              "      <td>8.84</td>\n",
              "      <td>21.55</td>\n",
              "      <td>31.08</td>\n",
              "      <td>47.97</td>\n",
              "      <td>69.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_annualized_food_inflation</th>\n",
              "      <td>25.0</td>\n",
              "      <td>12.1988</td>\n",
              "      <td>15.052045</td>\n",
              "      <td>1.24</td>\n",
              "      <td>3.58</td>\n",
              "      <td>6.68</td>\n",
              "      <td>10.79</td>\n",
              "      <td>55.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>maximum_food_drawdown</th>\n",
              "      <td>25.0</td>\n",
              "      <td>-22.8580</td>\n",
              "      <td>11.123922</td>\n",
              "      <td>-40.67</td>\n",
              "      <td>-31.98</td>\n",
              "      <td>-23.71</td>\n",
              "      <td>-13.96</td>\n",
              "      <td>-2.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_annualized_food_volatility</th>\n",
              "      <td>25.0</td>\n",
              "      <td>10.5904</td>\n",
              "      <td>5.413819</td>\n",
              "      <td>1.84</td>\n",
              "      <td>7.15</td>\n",
              "      <td>9.89</td>\n",
              "      <td>12.58</td>\n",
              "      <td>24.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>average_annual_food_price_correlation_between_markets</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.7756</td>\n",
              "      <td>0.186192</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index_confidence_score</th>\n",
              "      <td>25.0</td>\n",
              "      <td>0.9196</td>\n",
              "      <td>0.040772</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>open</th>\n",
              "      <td>25.0</td>\n",
              "      <td>7.0976</td>\n",
              "      <td>16.762704</td>\n",
              "      <td>1.07</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1.45</td>\n",
              "      <td>2.57</td>\n",
              "      <td>77.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    count     mean        std  \\\n",
              "number_of_markets_modeled                            25.0  56.4800  47.682212   \n",
              "number_of_markets_covered                            25.0  56.4800  47.682212   \n",
              "number_of_food_items                                 25.0   9.3200   7.016172   \n",
              "data_coverage_food                                   25.0  35.3404  17.451470   \n",
              "average_annualized_food_inflation                    25.0  12.1988  15.052045   \n",
              "maximum_food_drawdown                                25.0 -22.8580  11.123922   \n",
              "average_annualized_food_volatility                   25.0  10.5904   5.413819   \n",
              "average_annual_food_price_correlation_between_m...   25.0   0.7756   0.186192   \n",
              "index_confidence_score                               25.0   0.9196   0.040772   \n",
              "open                                                 25.0   7.0976  16.762704   \n",
              "\n",
              "                                                      min    25%    50%  \\\n",
              "number_of_markets_modeled                            9.00  24.00  42.00   \n",
              "number_of_markets_covered                            9.00  24.00  42.00   \n",
              "number_of_food_items                                 3.00   4.00   7.00   \n",
              "data_coverage_food                                   8.84  21.55  31.08   \n",
              "average_annualized_food_inflation                    1.24   3.58   6.68   \n",
              "maximum_food_drawdown                              -40.67 -31.98 -23.71   \n",
              "average_annualized_food_volatility                   1.84   7.15   9.89   \n",
              "average_annual_food_price_correlation_between_m...   0.27   0.67   0.82   \n",
              "index_confidence_score                               0.82   0.89   0.93   \n",
              "open                                                 1.07   1.40   1.45   \n",
              "\n",
              "                                                      75%     max  \n",
              "number_of_markets_modeled                           79.00  228.00  \n",
              "number_of_markets_covered                           79.00  228.00  \n",
              "number_of_food_items                                11.00   26.00  \n",
              "data_coverage_food                                  47.97   69.91  \n",
              "average_annualized_food_inflation                   10.79   55.30  \n",
              "maximum_food_drawdown                              -13.96   -2.79  \n",
              "average_annualized_food_volatility                  12.58   24.77  \n",
              "average_annual_food_price_correlation_between_m...   0.91    0.99  \n",
              "index_confidence_score                               0.95    0.99  \n",
              "open                                                 2.57   77.30  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top values for `country`:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "country\n",
              "Afghanistan             1\n",
              "Liberia                 1\n",
              "Chad                    1\n",
              "Syrian Arab Republic    1\n",
              "South Sudan             1\n",
              "Somalia                 1\n",
              "Sudan                   1\n",
              "Nigeria                 1\n",
              "Niger                   1\n",
              "Mozambique              1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top values for `currency`:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "currency\n",
              "XOF    4\n",
              "XAF    4\n",
              "AFN    1\n",
              "MMK    1\n",
              "SYP    1\n",
              "SSP    1\n",
              "SOS    1\n",
              "SDG    1\n",
              "NGN    1\n",
              "MZN    1\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save the merged cleaned dataset\n",
        "merged_out = \"data/food_price_merged_cleaned.csv\"\n",
        "merged.to_csv(merged_out, index=False)\n",
        "print(\"Saved merged cleaned dataset:\", merged_out)\n",
        "\n",
        "# Quick numeric summary (first 10 rows of summary only to keep output tidy)\n",
        "import numpy as np\n",
        "num_summary = merged.select_dtypes(include=[np.number]).describe().T.head(10)\n",
        "display(num_summary)\n",
        "\n",
        "# Frequent categories to guide EDA\n",
        "for key in [\"country\", \"item\", \"unit\", \"currency\", \"series\"]:\n",
        "    if key in merged.columns:\n",
        "        print(f\"\\nTop values for `{key}`:\")\n",
        "        display(merged[key].value_counts().head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 7\n",
        "\n",
        "## Feature Engineering\n",
        "\n",
        "Create new variables to enhance the dataset for analysis and modeling, grouped into logical categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.1 Extract year and month from a date column\n",
        "\n",
        "If date exists, split into numeric year and month for seasonal/time-based analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added year and month columns from date.\n"
          ]
        }
      ],
      "source": [
        "if \"date\" in merged.columns and pd.api.types.is_datetime64_any_dtype(merged[\"date\"]):\n",
        "    merged[\"year\"] = merged[\"date\"].dt.year\n",
        "    merged[\"month\"] = merged[\"date\"].dt.month\n",
        "    print(\"Added year and month columns from date.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.2 Calculate month-on-month percentage change for close price\n",
        "\n",
        "Tracks short-term price momentum per country."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added month-on-month close percentage change.\n"
          ]
        }
      ],
      "source": [
        "if {\"country\", \"date\", \"close\"}.issubset(merged.columns):\n",
        "    merged = merged.sort_values([\"country\", \"date\"])\n",
        "    merged[\"close_pct_change\"] = merged.groupby(\"country\")[\"close\"].pct_change()\n",
        "    print(\"Added month-on-month close percentage change.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.3 Calculate a 3-month rolling average for close\n",
        "\n",
        "Smooths price fluctuations for trend analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 3-month rolling average for close price.\n"
          ]
        }
      ],
      "source": [
        "if {\"country\", \"close\"}.issubset(merged.columns):\n",
        "    merged[\"close_rolling_avg_3\"] = (\n",
        "        merged.groupby(\"country\")[\"close\"]\n",
        "              .transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
        "    )\n",
        "    print(\"Added 3-month rolling average for close price.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.4 Calculate year-on-year percentage change for close\n",
        "\n",
        "Highlights long-term trends by comparing to the same month last year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added year-on-year close percentage change.\n"
          ]
        }
      ],
      "source": [
        "if {\"country\", \"date\", \"close\"}.issubset(merged.columns):\n",
        "    merged[\"close_yoy_change\"] = merged.groupby(\"country\")[\"close\"].pct_change(periods=12)\n",
        "    print(\"Added year-on-year close percentage change.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.5 One-hot encode the item column\n",
        "\n",
        "Converts item categories into separate binary columns for modelling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"item\" in merged.columns:\n",
        "    merged = pd.get_dummies(merged, columns=[\"item\"], prefix=\"item\")\n",
        "    print(\"One-hot encoded the item column.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.6 Create inflation bands\n",
        "\n",
        "Groups inflation values into named categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added inflation bands.\n"
          ]
        }
      ],
      "source": [
        "if \"inflation\" in merged.columns:\n",
        "    bins = [-float(\"inf\"), 0, 5, 10, float(\"inf\")]\n",
        "    labels = [\"deflation\", \"low\", \"medium\", \"high\"]\n",
        "    merged[\"inflation_band\"] = pd.cut(merged[\"inflation\"], bins=bins, labels=labels)\n",
        "    print(\"Added inflation bands.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.7 Calculate average close price per country-item\n",
        "\n",
        "Captures cross-category pricing patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "if {\"country\", \"item\", \"close\"}.issubset(merged.columns):\n",
        "    merged[\"country_item_avg_close\"] = (\n",
        "        merged.groupby([\"country\", \"item\"])[\"close\"].transform(\"mean\")\n",
        "    )\n",
        "    print(\"Added average close price per country-item.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.8 Calculate days since last observation\n",
        "\n",
        "Flags irregular time gaps in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added days since last observation.\n"
          ]
        }
      ],
      "source": [
        "if {\"country\", \"date\"}.issubset(merged.columns) and pd.api.types.is_datetime64_any_dtype(merged[\"date\"]):\n",
        "    merged = merged.sort_values([\"country\", \"date\"])\n",
        "    merged[\"days_since_last\"] = merged.groupby(\"country\")[\"date\"].diff().dt.days\n",
        "    print(\"Added days since last observation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.9 Flag missing inflation values\n",
        "\n",
        "Allows models to consider “missingness” as a potential signal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added missing value flag for inflation.\n"
          ]
        }
      ],
      "source": [
        "if \"inflation\" in merged.columns:\n",
        "    merged[\"inflation_missing\"] = merged[\"inflation\"].isna().astype(int)\n",
        "    print(\"Added missing value flag for inflation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 8\n",
        "\n",
        "## Preparing the Feature Engineered Dataset\n",
        "\n",
        "After completing my feature engineering process, I need to optimize the dataset for analysis. In this step, I apply column reduction to remove redundant, technical, and low-value columns that aren't needed for visualization and basic analysis.\n",
        "\n",
        "My approach is to:\n",
        "- Remove redundant date columns while keeping the main 'date' field\n",
        "- Drop technical modeling columns that are only useful for advanced statistical analysis\n",
        "- Remove correlation columns that add complexity without immediate value\n",
        "- Eliminate failed feature engineering columns (like unsuccessful percentage changes)\n",
        "- Drop one-hot encoded item columns with very low frequency (less than 10 occurrences)\n",
        "\n",
        "This process reduces the dataset from 36 columns to approximately 18 columns, making it more manageable while retaining all the essential information for food price inflation analysis.\n",
        "\n",
        "I will perform validation and cleanup before saving the final dataset in Section 10.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape before column reduction: (25, 36)\n",
            "Columns to drop: ['end_date_observations', 'start_date_observations', 'number_of_markets_modeled', 'number_of_markets_covered', 'number_of_observations_food', 'number_of_observations_other', 'rsquared_individual_food_items', 'rsquared_individual_other_items', 'index_confidence_score', 'imputation_model', 'average_monthly_food_price_correlation_between_markets', 'average_annual_food_price_correlation_between_markets', 'close_yoy_change', 'days_since_last']\n",
            "Dataset shape after column reduction: (25, 22)\n",
            "Dropped 14 columns\n",
            "Dataset prepared for validation and final save...\n"
          ]
        }
      ],
      "source": [
        "## Preparing the Feature Engineered Dataset\n",
        "\n",
        "# Apply column reduction before validation\n",
        "print(f\"Dataset shape before column reduction: {merged.shape}\")\n",
        "\n",
        "# Define columns to drop\n",
        "columns_to_drop = [\n",
        "    # Redundant date columns (keep 'date' instead)\n",
        "    'end_date_observations', 'start_date_observations',\n",
        "    \n",
        "    # Technical/modeling columns not needed for visualization\n",
        "    'number_of_markets_modeled', 'number_of_markets_covered',\n",
        "    'number_of_observations_food', 'number_of_observations_other',\n",
        "    'rsquared_individual_food_items', 'rsquared_individual_other_items',\n",
        "    'index_confidence_score', 'imputation_model',\n",
        "    \n",
        "    # Correlation columns\n",
        "    'average_monthly_food_price_correlation_between_markets',\n",
        "    'average_annual_food_price_correlation_between_markets',\n",
        "    \n",
        "    # Less useful engineered columns for basic visualization\n",
        "    'close_yoy_change', 'country_item_avg_close', 'days_since_last'\n",
        "]\n",
        "\n",
        "# Drop one-hot encoded item columns with low frequency (less than 10 occurrences)\n",
        "item_cols_to_drop = [col for col in merged.columns if col.startswith('item_') and merged[col].sum() < 10]\n",
        "columns_to_drop.extend(item_cols_to_drop)\n",
        "\n",
        "# Remove columns that actually exist in the dataset\n",
        "columns_to_drop = [col for col in columns_to_drop if col in merged.columns]\n",
        "\n",
        "print(f\"Columns to drop: {columns_to_drop}\")\n",
        "\n",
        "# Drop the columns and duplicates\n",
        "merged_reduced = merged.drop(columns=columns_to_drop)\n",
        "merged_reduced = merged_reduced.drop_duplicates()\n",
        "\n",
        "print(f\"Dataset shape after column reduction: {merged_reduced.shape}\")\n",
        "print(f\"Dropped {len(columns_to_drop)} columns\")\n",
        "\n",
        "# Proceeding to validation and final cleanup in Section 10\n",
        "print(\"Dataset prepared for validation and final save...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 9\n",
        "\n",
        "## Final Dataset Validation\n",
        "\n",
        "Before considering my ETL process complete, I perform a comprehensive validation check to ensure data quality. This validation process examines multiple aspects of the dataset:\n",
        "\n",
        "### Data Quality Checks I Perform:\n",
        "\n",
        "1. **Duplicate Column Names**: I check if any columns have identical names, which would cause issues in analysis\n",
        "2. **Identical Content**: I identify columns that contain exactly the same data (redundant columns)\n",
        "3. **Empty Columns**: I find columns that are completely null or empty\n",
        "4. **High Missing Values**: I flag columns with more than 95% missing data\n",
        "5. **Single-Value Columns**: I identify columns with no variance (only one unique value)\n",
        "6. **Suspicious Patterns**: I look for unnamed columns or index-like artifacts\n",
        "\n",
        "### Dataset Summary:\n",
        "\n",
        "The validation also provides a comprehensive summary including:\n",
        "- Dataset shape and memory usage\n",
        "- Column type distribution\n",
        "- Complete list of all columns for manual review\n",
        "\n",
        "This step is crucial because it reveals any remaining data quality issues that could affect downstream analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== FINAL VALIDATION CHECK FOR FOOD PRICE FEATURE ENGINEERED ===\n",
            "\n",
            "✅ No duplicate column names\n",
            "⚠️ COLUMNS WITH IDENTICAL CONTENT: [('iso3', 'iso3_country'), ('close', 'close_rolling_avg_3')]\n",
            "⚠️ COMPLETELY EMPTY COLUMNS: ['close_pct_change']\n",
            "⚠️ COLUMNS WITH >95% MISSING VALUES: ['close_pct_change']\n",
            "⚠️ SINGLE-VALUE COLUMNS (NO VARIANCE): ['close_pct_change', 'inflation_missing']\n",
            "✅ No suspicious column patterns\n",
            "\n",
            "📊 DATASET SUMMARY:\n",
            "   Shape: (25, 22)\n",
            "   Total columns: 22\n",
            "   Total rows: 25\n",
            "   Duplicate rows: 0\n",
            "   Memory usage: 0.02 MB\n",
            "\n",
            "📋 COLUMN TYPES:\n",
            "{dtype('float64'): 11, dtype('O'): 5, dtype('int64'): 2, dtype('int32'): 2, dtype('<M8[ns]'): 1, CategoricalDtype(categories=['deflation', 'low', 'medium', 'high'], ordered=True, categories_dtype=object): 1}\n",
            "\n",
            "📝 ALL COLUMNS (22):\n",
            "    1. country\n",
            "    2. iso3\n",
            "    3. components\n",
            "    4. currency\n",
            "    5. number_of_food_items\n",
            "    6. data_coverage_food\n",
            "    7. average_annualized_food_inflation\n",
            "    8. maximum_food_drawdown\n",
            "    9. average_annualized_food_volatility\n",
            "   10. date\n",
            "   11. open\n",
            "   12. high\n",
            "   13. low\n",
            "   14. close\n",
            "   15. inflation\n",
            "   16. iso3_country\n",
            "   17. year\n",
            "   18. month\n",
            "   19. close_pct_change\n",
            "   20. close_rolling_avg_3\n",
            "   21. inflation_band\n",
            "   22. inflation_missing\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>iso3</th>\n",
              "      <th>components</th>\n",
              "      <th>currency</th>\n",
              "      <th>number_of_food_items</th>\n",
              "      <th>data_coverage_food</th>\n",
              "      <th>average_annualized_food_inflation</th>\n",
              "      <th>maximum_food_drawdown</th>\n",
              "      <th>average_annualized_food_volatility</th>\n",
              "      <th>date</th>\n",
              "      <th>...</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>inflation</th>\n",
              "      <th>iso3_country</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>close_pct_change</th>\n",
              "      <th>close_rolling_avg_3</th>\n",
              "      <th>inflation_band</th>\n",
              "      <th>inflation_missing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>AFG</td>\n",
              "      <td>Bread (1 KG, Index Weight = 1), Rice (Low Qual...</td>\n",
              "      <td>AFN</td>\n",
              "      <td>3</td>\n",
              "      <td>31.77</td>\n",
              "      <td>6.06</td>\n",
              "      <td>-40.67</td>\n",
              "      <td>7.93</td>\n",
              "      <td>2023-09-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.42</td>\n",
              "      <td>-6.50</td>\n",
              "      <td>AFG</td>\n",
              "      <td>2023</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.42</td>\n",
              "      <td>deflation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Burkina Faso</td>\n",
              "      <td>BFA</td>\n",
              "      <td>Maize (White) (1 KG, Index Weight = 1), Millet...</td>\n",
              "      <td>XOF</td>\n",
              "      <td>3</td>\n",
              "      <td>55.20</td>\n",
              "      <td>6.81</td>\n",
              "      <td>-36.70</td>\n",
              "      <td>13.71</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.45</td>\n",
              "      <td>-15.91</td>\n",
              "      <td>BFA</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.45</td>\n",
              "      <td>deflation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Burundi</td>\n",
              "      <td>BDI</td>\n",
              "      <td>Bananas (1 KG, Index Weight = 1), Beans (1 KG,...</td>\n",
              "      <td>BIF</td>\n",
              "      <td>10</td>\n",
              "      <td>38.24</td>\n",
              "      <td>7.86</td>\n",
              "      <td>-30.77</td>\n",
              "      <td>12.03</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.87</td>\n",
              "      <td>1.88</td>\n",
              "      <td>26.79</td>\n",
              "      <td>BDI</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.88</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cameroon</td>\n",
              "      <td>CMR</td>\n",
              "      <td>Bananas (12 KG, Index Weight = 0.08), Cassava ...</td>\n",
              "      <td>XAF</td>\n",
              "      <td>10</td>\n",
              "      <td>8.84</td>\n",
              "      <td>2.47</td>\n",
              "      <td>-2.79</td>\n",
              "      <td>1.84</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.28</td>\n",
              "      <td>1.29</td>\n",
              "      <td>2.28</td>\n",
              "      <td>CMR</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.29</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Central African Republic</td>\n",
              "      <td>CAF</td>\n",
              "      <td>Cassava (Cossette) (1 KG, Index Weight = 1), M...</td>\n",
              "      <td>XAF</td>\n",
              "      <td>5</td>\n",
              "      <td>24.85</td>\n",
              "      <td>5.22</td>\n",
              "      <td>-24.85</td>\n",
              "      <td>13.74</td>\n",
              "      <td>2023-06-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.36</td>\n",
              "      <td>1.43</td>\n",
              "      <td>0.04</td>\n",
              "      <td>CAF</td>\n",
              "      <td>2023</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.43</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Chad</td>\n",
              "      <td>TCD</td>\n",
              "      <td>Maize (White) (1 KG, Index Weight = 1), Millet...</td>\n",
              "      <td>XAF</td>\n",
              "      <td>4</td>\n",
              "      <td>27.41</td>\n",
              "      <td>3.16</td>\n",
              "      <td>-32.67</td>\n",
              "      <td>12.58</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.38</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0.99</td>\n",
              "      <td>TCD</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.40</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Congo, Dem. Rep.</td>\n",
              "      <td>COD</td>\n",
              "      <td>Beans (1 KG, Index Weight = 1), Cassava (Cosse...</td>\n",
              "      <td>CDF</td>\n",
              "      <td>17</td>\n",
              "      <td>15.65</td>\n",
              "      <td>6.64</td>\n",
              "      <td>-15.73</td>\n",
              "      <td>6.99</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.39</td>\n",
              "      <td>1.39</td>\n",
              "      <td>14.09</td>\n",
              "      <td>COD</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.39</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Congo, Rep.</td>\n",
              "      <td>COG</td>\n",
              "      <td>Beans (White) (1 KG, Index Weight = 1), Cassav...</td>\n",
              "      <td>XAF</td>\n",
              "      <td>4</td>\n",
              "      <td>29.37</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-8.13</td>\n",
              "      <td>5.45</td>\n",
              "      <td>2022-04-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1.06</td>\n",
              "      <td>4.14</td>\n",
              "      <td>COG</td>\n",
              "      <td>2022</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.06</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gambia, The</td>\n",
              "      <td>GMB</td>\n",
              "      <td>Apples (Red) (1 KG, Index Weight = 1), Bananas...</td>\n",
              "      <td>GMD</td>\n",
              "      <td>26</td>\n",
              "      <td>31.08</td>\n",
              "      <td>6.68</td>\n",
              "      <td>-20.83</td>\n",
              "      <td>7.15</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.69</td>\n",
              "      <td>1.70</td>\n",
              "      <td>21.56</td>\n",
              "      <td>GMB</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.70</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Guinea-Bissau</td>\n",
              "      <td>GNB</td>\n",
              "      <td>Millet (1 KG, Index Weight = 1), Oil (Vegetabl...</td>\n",
              "      <td>XOF</td>\n",
              "      <td>5</td>\n",
              "      <td>15.61</td>\n",
              "      <td>1.62</td>\n",
              "      <td>-28.04</td>\n",
              "      <td>11.77</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.42</td>\n",
              "      <td>1.43</td>\n",
              "      <td>3.81</td>\n",
              "      <td>GNB</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.43</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Haiti</td>\n",
              "      <td>HTI</td>\n",
              "      <td>Beans (Black) (1 Marmite, Index Weight = 0.37)...</td>\n",
              "      <td>HTG</td>\n",
              "      <td>8</td>\n",
              "      <td>62.29</td>\n",
              "      <td>12.36</td>\n",
              "      <td>-31.98</td>\n",
              "      <td>11.66</td>\n",
              "      <td>2023-06-01</td>\n",
              "      <td>...</td>\n",
              "      <td>3.70</td>\n",
              "      <td>4.03</td>\n",
              "      <td>48.44</td>\n",
              "      <td>HTI</td>\n",
              "      <td>2023</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.03</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Iraq</td>\n",
              "      <td>IRQ</td>\n",
              "      <td>Beans (White) (1 KG, Index Weight = 1), Bread ...</td>\n",
              "      <td>IQD</td>\n",
              "      <td>18</td>\n",
              "      <td>56.52</td>\n",
              "      <td>1.25</td>\n",
              "      <td>-14.16</td>\n",
              "      <td>3.64</td>\n",
              "      <td>2023-09-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.26</td>\n",
              "      <td>1.27</td>\n",
              "      <td>7.38</td>\n",
              "      <td>IRQ</td>\n",
              "      <td>2023</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.27</td>\n",
              "      <td>medium</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Lao Pdr</td>\n",
              "      <td>LAO</td>\n",
              "      <td>Eggs (1 Unit, Index Weight = 12), Fish (Catfis...</td>\n",
              "      <td>LAK</td>\n",
              "      <td>11</td>\n",
              "      <td>61.50</td>\n",
              "      <td>6.56</td>\n",
              "      <td>-7.92</td>\n",
              "      <td>3.60</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.73</td>\n",
              "      <td>1.74</td>\n",
              "      <td>27.13</td>\n",
              "      <td>LAO</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.74</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Lebanon</td>\n",
              "      <td>LBN</td>\n",
              "      <td>Beans (White) (1 KG, Index Weight = 1), Bread ...</td>\n",
              "      <td>LBP</td>\n",
              "      <td>22</td>\n",
              "      <td>60.62</td>\n",
              "      <td>41.49</td>\n",
              "      <td>-12.13</td>\n",
              "      <td>18.17</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>40.01</td>\n",
              "      <td>40.43</td>\n",
              "      <td>139.28</td>\n",
              "      <td>LBN</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.43</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Liberia</td>\n",
              "      <td>LBR</td>\n",
              "      <td>Cassava (Fresh) (50 KG, Index Weight = 0.02), ...</td>\n",
              "      <td>LRD</td>\n",
              "      <td>4</td>\n",
              "      <td>33.46</td>\n",
              "      <td>7.74</td>\n",
              "      <td>-10.82</td>\n",
              "      <td>7.98</td>\n",
              "      <td>2020-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.43</td>\n",
              "      <td>1.49</td>\n",
              "      <td>6.41</td>\n",
              "      <td>LBR</td>\n",
              "      <td>2020</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.49</td>\n",
              "      <td>medium</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Mali</td>\n",
              "      <td>MLI</td>\n",
              "      <td>Beans (Niebe) (1 KG, Index Weight = 1), Maize ...</td>\n",
              "      <td>XOF</td>\n",
              "      <td>5</td>\n",
              "      <td>43.63</td>\n",
              "      <td>3.58</td>\n",
              "      <td>-38.68</td>\n",
              "      <td>8.26</td>\n",
              "      <td>2023-06-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.34</td>\n",
              "      <td>1.34</td>\n",
              "      <td>-11.62</td>\n",
              "      <td>MLI</td>\n",
              "      <td>2023</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.34</td>\n",
              "      <td>deflation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Mozambique</td>\n",
              "      <td>MOZ</td>\n",
              "      <td>Cowpeas (1 KG, Index Weight = 1), Maize (White...</td>\n",
              "      <td>MZN</td>\n",
              "      <td>7</td>\n",
              "      <td>19.17</td>\n",
              "      <td>7.64</td>\n",
              "      <td>-22.60</td>\n",
              "      <td>6.60</td>\n",
              "      <td>2023-02-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.44</td>\n",
              "      <td>1.46</td>\n",
              "      <td>3.99</td>\n",
              "      <td>MOZ</td>\n",
              "      <td>2023</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.46</td>\n",
              "      <td>low</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Myanmar</td>\n",
              "      <td>MMR</td>\n",
              "      <td>Pulses (1 KG, Index Weight = 1), Rice (Low Qua...</td>\n",
              "      <td>MMK</td>\n",
              "      <td>3</td>\n",
              "      <td>15.70</td>\n",
              "      <td>10.79</td>\n",
              "      <td>-23.71</td>\n",
              "      <td>9.89</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.52</td>\n",
              "      <td>2.56</td>\n",
              "      <td>62.34</td>\n",
              "      <td>MMR</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.56</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Niger</td>\n",
              "      <td>NER</td>\n",
              "      <td>Millet (1 KG, Index Weight = 1), Rice (Importe...</td>\n",
              "      <td>XOF</td>\n",
              "      <td>3</td>\n",
              "      <td>69.91</td>\n",
              "      <td>2.99</td>\n",
              "      <td>-23.76</td>\n",
              "      <td>9.54</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.16</td>\n",
              "      <td>1.22</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>NER</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.22</td>\n",
              "      <td>deflation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Nigeria</td>\n",
              "      <td>NGA</td>\n",
              "      <td>Cassava Meal (Gari, Yellow) (100 KG, Index Wei...</td>\n",
              "      <td>NGN</td>\n",
              "      <td>8</td>\n",
              "      <td>21.55</td>\n",
              "      <td>8.21</td>\n",
              "      <td>-37.05</td>\n",
              "      <td>11.84</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.74</td>\n",
              "      <td>1.78</td>\n",
              "      <td>6.83</td>\n",
              "      <td>NGA</td>\n",
              "      <td>2023</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.78</td>\n",
              "      <td>medium</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Somalia</td>\n",
              "      <td>SOM</td>\n",
              "      <td>Maize (White) (1 KG, Index Weight = 1), Milk (...</td>\n",
              "      <td>SOS</td>\n",
              "      <td>5</td>\n",
              "      <td>19.65</td>\n",
              "      <td>4.91</td>\n",
              "      <td>-37.03</td>\n",
              "      <td>9.54</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.33</td>\n",
              "      <td>1.37</td>\n",
              "      <td>-14.56</td>\n",
              "      <td>SOM</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.37</td>\n",
              "      <td>deflation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>South Sudan</td>\n",
              "      <td>SSD</td>\n",
              "      <td>Beans (Red) (1 KG, Index Weight = 1), Cassava ...</td>\n",
              "      <td>SSP</td>\n",
              "      <td>9</td>\n",
              "      <td>24.84</td>\n",
              "      <td>47.02</td>\n",
              "      <td>-29.43</td>\n",
              "      <td>22.75</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>8.13</td>\n",
              "      <td>8.13</td>\n",
              "      <td>73.82</td>\n",
              "      <td>SSD</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.13</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Sudan</td>\n",
              "      <td>SDN</td>\n",
              "      <td>Millet (3.5 KG, Index Weight = 0.29), Sorghum ...</td>\n",
              "      <td>SDG</td>\n",
              "      <td>4</td>\n",
              "      <td>40.12</td>\n",
              "      <td>55.30</td>\n",
              "      <td>-12.16</td>\n",
              "      <td>24.77</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>...</td>\n",
              "      <td>74.61</td>\n",
              "      <td>75.16</td>\n",
              "      <td>34.75</td>\n",
              "      <td>SDN</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>75.16</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Syrian Arab Republic</td>\n",
              "      <td>SYR</td>\n",
              "      <td>Apples (1 KG, Index Weight = 1), Bananas (1 KG...</td>\n",
              "      <td>SYP</td>\n",
              "      <td>24</td>\n",
              "      <td>28.56</td>\n",
              "      <td>34.15</td>\n",
              "      <td>-13.96</td>\n",
              "      <td>12.68</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>15.45</td>\n",
              "      <td>15.45</td>\n",
              "      <td>69.08</td>\n",
              "      <td>SYR</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.45</td>\n",
              "      <td>high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Yemen, Rep.</td>\n",
              "      <td>YEM</td>\n",
              "      <td>Beans (Kidney Red) (1 KG, Index Weight = 1), E...</td>\n",
              "      <td>YER</td>\n",
              "      <td>15</td>\n",
              "      <td>47.97</td>\n",
              "      <td>13.22</td>\n",
              "      <td>-14.88</td>\n",
              "      <td>10.65</td>\n",
              "      <td>2023-07-01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.75</td>\n",
              "      <td>2.81</td>\n",
              "      <td>-1.85</td>\n",
              "      <td>YEM</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.81</td>\n",
              "      <td>deflation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     country iso3  \\\n",
              "0                Afghanistan  AFG   \n",
              "2               Burkina Faso  BFA   \n",
              "1                    Burundi  BDI   \n",
              "4                   Cameroon  CMR   \n",
              "3   Central African Republic  CAF   \n",
              "23                      Chad  TCD   \n",
              "5           Congo, Dem. Rep.  COD   \n",
              "6                Congo, Rep.  COG   \n",
              "7                Gambia, The  GMB   \n",
              "8              Guinea-Bissau  GNB   \n",
              "9                      Haiti  HTI   \n",
              "10                      Iraq  IRQ   \n",
              "11                   Lao Pdr  LAO   \n",
              "12                   Lebanon  LBN   \n",
              "13                   Liberia  LBR   \n",
              "14                      Mali  MLI   \n",
              "16                Mozambique  MOZ   \n",
              "15                   Myanmar  MMR   \n",
              "17                     Niger  NER   \n",
              "18                   Nigeria  NGA   \n",
              "20                   Somalia  SOM   \n",
              "21               South Sudan  SSD   \n",
              "19                     Sudan  SDN   \n",
              "22      Syrian Arab Republic  SYR   \n",
              "24               Yemen, Rep.  YEM   \n",
              "\n",
              "                                           components currency  \\\n",
              "0   Bread (1 KG, Index Weight = 1), Rice (Low Qual...      AFN   \n",
              "2   Maize (White) (1 KG, Index Weight = 1), Millet...      XOF   \n",
              "1   Bananas (1 KG, Index Weight = 1), Beans (1 KG,...      BIF   \n",
              "4   Bananas (12 KG, Index Weight = 0.08), Cassava ...      XAF   \n",
              "3   Cassava (Cossette) (1 KG, Index Weight = 1), M...      XAF   \n",
              "23  Maize (White) (1 KG, Index Weight = 1), Millet...      XAF   \n",
              "5   Beans (1 KG, Index Weight = 1), Cassava (Cosse...      CDF   \n",
              "6   Beans (White) (1 KG, Index Weight = 1), Cassav...      XAF   \n",
              "7   Apples (Red) (1 KG, Index Weight = 1), Bananas...      GMD   \n",
              "8   Millet (1 KG, Index Weight = 1), Oil (Vegetabl...      XOF   \n",
              "9   Beans (Black) (1 Marmite, Index Weight = 0.37)...      HTG   \n",
              "10  Beans (White) (1 KG, Index Weight = 1), Bread ...      IQD   \n",
              "11  Eggs (1 Unit, Index Weight = 12), Fish (Catfis...      LAK   \n",
              "12  Beans (White) (1 KG, Index Weight = 1), Bread ...      LBP   \n",
              "13  Cassava (Fresh) (50 KG, Index Weight = 0.02), ...      LRD   \n",
              "14  Beans (Niebe) (1 KG, Index Weight = 1), Maize ...      XOF   \n",
              "16  Cowpeas (1 KG, Index Weight = 1), Maize (White...      MZN   \n",
              "15  Pulses (1 KG, Index Weight = 1), Rice (Low Qua...      MMK   \n",
              "17  Millet (1 KG, Index Weight = 1), Rice (Importe...      XOF   \n",
              "18  Cassava Meal (Gari, Yellow) (100 KG, Index Wei...      NGN   \n",
              "20  Maize (White) (1 KG, Index Weight = 1), Milk (...      SOS   \n",
              "21  Beans (Red) (1 KG, Index Weight = 1), Cassava ...      SSP   \n",
              "19  Millet (3.5 KG, Index Weight = 0.29), Sorghum ...      SDG   \n",
              "22  Apples (1 KG, Index Weight = 1), Bananas (1 KG...      SYP   \n",
              "24  Beans (Kidney Red) (1 KG, Index Weight = 1), E...      YER   \n",
              "\n",
              "    number_of_food_items  data_coverage_food  \\\n",
              "0                      3               31.77   \n",
              "2                      3               55.20   \n",
              "1                     10               38.24   \n",
              "4                     10                8.84   \n",
              "3                      5               24.85   \n",
              "23                     4               27.41   \n",
              "5                     17               15.65   \n",
              "6                      4               29.37   \n",
              "7                     26               31.08   \n",
              "8                      5               15.61   \n",
              "9                      8               62.29   \n",
              "10                    18               56.52   \n",
              "11                    11               61.50   \n",
              "12                    22               60.62   \n",
              "13                     4               33.46   \n",
              "14                     5               43.63   \n",
              "16                     7               19.17   \n",
              "15                     3               15.70   \n",
              "17                     3               69.91   \n",
              "18                     8               21.55   \n",
              "20                     5               19.65   \n",
              "21                     9               24.84   \n",
              "19                     4               40.12   \n",
              "22                    24               28.56   \n",
              "24                    15               47.97   \n",
              "\n",
              "    average_annualized_food_inflation  maximum_food_drawdown  \\\n",
              "0                                6.06                 -40.67   \n",
              "2                                6.81                 -36.70   \n",
              "1                                7.86                 -30.77   \n",
              "4                                2.47                  -2.79   \n",
              "3                                5.22                 -24.85   \n",
              "23                               3.16                 -32.67   \n",
              "5                                6.64                 -15.73   \n",
              "6                                1.24                  -8.13   \n",
              "7                                6.68                 -20.83   \n",
              "8                                1.62                 -28.04   \n",
              "9                               12.36                 -31.98   \n",
              "10                               1.25                 -14.16   \n",
              "11                               6.56                  -7.92   \n",
              "12                              41.49                 -12.13   \n",
              "13                               7.74                 -10.82   \n",
              "14                               3.58                 -38.68   \n",
              "16                               7.64                 -22.60   \n",
              "15                              10.79                 -23.71   \n",
              "17                               2.99                 -23.76   \n",
              "18                               8.21                 -37.05   \n",
              "20                               4.91                 -37.03   \n",
              "21                              47.02                 -29.43   \n",
              "19                              55.30                 -12.16   \n",
              "22                              34.15                 -13.96   \n",
              "24                              13.22                 -14.88   \n",
              "\n",
              "    average_annualized_food_volatility       date  ...    low  close  \\\n",
              "0                                 7.93 2023-09-01  ...   1.42   1.42   \n",
              "2                                13.71 2023-07-01  ...   1.42   1.45   \n",
              "1                                12.03 2023-08-01  ...   1.87   1.88   \n",
              "4                                 1.84 2023-08-01  ...   1.28   1.29   \n",
              "3                                13.74 2023-06-01  ...   1.36   1.43   \n",
              "23                               12.58 2023-08-01  ...   1.38   1.40   \n",
              "5                                 6.99 2023-01-01  ...   1.39   1.39   \n",
              "6                                 5.45 2022-04-01  ...   1.05   1.06   \n",
              "7                                 7.15 2023-07-01  ...   1.69   1.70   \n",
              "8                                11.77 2023-08-01  ...   1.42   1.43   \n",
              "9                                11.66 2023-06-01  ...   3.70   4.03   \n",
              "10                                3.64 2023-09-01  ...   1.26   1.27   \n",
              "11                                3.60 2023-07-01  ...   1.73   1.74   \n",
              "12                               18.17 2023-08-01  ...  40.01  40.43   \n",
              "13                                7.98 2020-08-01  ...   1.43   1.49   \n",
              "14                                8.26 2023-06-01  ...   1.34   1.34   \n",
              "16                                6.60 2023-02-01  ...   1.44   1.46   \n",
              "15                                9.89 2023-08-01  ...   2.52   2.56   \n",
              "17                                9.54 2023-07-01  ...   1.16   1.22   \n",
              "18                               11.84 2023-01-01  ...   1.74   1.78   \n",
              "20                                9.54 2023-07-01  ...   1.33   1.37   \n",
              "21                               22.75 2023-08-01  ...   8.13   8.13   \n",
              "19                               24.77 2023-08-01  ...  74.61  75.16   \n",
              "22                               12.68 2023-07-01  ...  15.45  15.45   \n",
              "24                               10.65 2023-07-01  ...   2.75   2.81   \n",
              "\n",
              "    inflation  iso3_country  year month  close_pct_change  \\\n",
              "0       -6.50           AFG  2023     9               NaN   \n",
              "2      -15.91           BFA  2023     7               NaN   \n",
              "1       26.79           BDI  2023     8               NaN   \n",
              "4        2.28           CMR  2023     8               NaN   \n",
              "3        0.04           CAF  2023     6               NaN   \n",
              "23       0.99           TCD  2023     8               NaN   \n",
              "5       14.09           COD  2023     1               NaN   \n",
              "6        4.14           COG  2022     4               NaN   \n",
              "7       21.56           GMB  2023     7               NaN   \n",
              "8        3.81           GNB  2023     8               NaN   \n",
              "9       48.44           HTI  2023     6               NaN   \n",
              "10       7.38           IRQ  2023     9               NaN   \n",
              "11      27.13           LAO  2023     7               NaN   \n",
              "12     139.28           LBN  2023     8               NaN   \n",
              "13       6.41           LBR  2020     8               NaN   \n",
              "14     -11.62           MLI  2023     6               NaN   \n",
              "16       3.99           MOZ  2023     2               NaN   \n",
              "15      62.34           MMR  2023     8               NaN   \n",
              "17      -0.61           NER  2023     7               NaN   \n",
              "18       6.83           NGA  2023     1               NaN   \n",
              "20     -14.56           SOM  2023     7               NaN   \n",
              "21      73.82           SSD  2023     8               NaN   \n",
              "19      34.75           SDN  2023     8               NaN   \n",
              "22      69.08           SYR  2023     7               NaN   \n",
              "24      -1.85           YEM  2023     7               NaN   \n",
              "\n",
              "    close_rolling_avg_3  inflation_band  inflation_missing  \n",
              "0                  1.42       deflation                  0  \n",
              "2                  1.45       deflation                  0  \n",
              "1                  1.88            high                  0  \n",
              "4                  1.29             low                  0  \n",
              "3                  1.43             low                  0  \n",
              "23                 1.40             low                  0  \n",
              "5                  1.39            high                  0  \n",
              "6                  1.06             low                  0  \n",
              "7                  1.70            high                  0  \n",
              "8                  1.43             low                  0  \n",
              "9                  4.03            high                  0  \n",
              "10                 1.27          medium                  0  \n",
              "11                 1.74            high                  0  \n",
              "12                40.43            high                  0  \n",
              "13                 1.49          medium                  0  \n",
              "14                 1.34       deflation                  0  \n",
              "16                 1.46             low                  0  \n",
              "15                 2.56            high                  0  \n",
              "17                 1.22       deflation                  0  \n",
              "18                 1.78          medium                  0  \n",
              "20                 1.37       deflation                  0  \n",
              "21                 8.13            high                  0  \n",
              "19                75.16            high                  0  \n",
              "22                15.45            high                  0  \n",
              "24                 2.81       deflation                  0  \n",
              "\n",
              "[25 rows x 22 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Final Dataset Validation Check\n",
        "def final_dataset_check(df, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Comprehensive final check for duplicate columns, irrelevant columns, and data quality\n",
        "    \"\"\"\n",
        "    print(f\"=== FINAL VALIDATION CHECK FOR {dataset_name.upper()} ===\\n\")\n",
        "    \n",
        "    # 1. Check for duplicate column names\n",
        "    duplicate_cols = df.columns[df.columns.duplicated()].tolist()\n",
        "    if duplicate_cols:\n",
        "        print(f\"⚠️ DUPLICATE COLUMN NAMES FOUND: {duplicate_cols}\")\n",
        "    else:\n",
        "        print(\"✅ No duplicate column names\")\n",
        "    \n",
        "    # 2. Check for columns with identical content\n",
        "    identical_cols = []\n",
        "    cols = df.columns.tolist()\n",
        "    for i in range(len(cols)):\n",
        "        for j in range(i+1, len(cols)):\n",
        "            if df[cols[i]].equals(df[cols[j]]):\n",
        "                identical_cols.append((cols[i], cols[j]))\n",
        "    \n",
        "    if identical_cols:\n",
        "        print(f\"⚠️ COLUMNS WITH IDENTICAL CONTENT: {identical_cols}\")\n",
        "    else:\n",
        "        print(\"✅ No columns with identical content\")\n",
        "    \n",
        "    # 3. Check for columns that are all null/empty\n",
        "    empty_cols = df.columns[df.isnull().all()].tolist()\n",
        "    if empty_cols:\n",
        "        print(f\"⚠️ COMPLETELY EMPTY COLUMNS: {empty_cols}\")\n",
        "    else:\n",
        "        print(\"✅ No completely empty columns\")\n",
        "    \n",
        "    # 4. Check for columns with very high missing values (>95%)\n",
        "    high_missing = df.columns[df.isnull().mean() > 0.95].tolist()\n",
        "    if high_missing:\n",
        "        print(f\"⚠️ COLUMNS WITH >95% MISSING VALUES: {high_missing}\")\n",
        "    else:\n",
        "        print(\"✅ No columns with excessive missing values\")\n",
        "    \n",
        "    # 5. Check for single-value columns (no variance)\n",
        "    single_value_cols = []\n",
        "    for col in df.columns:\n",
        "        if df[col].nunique() <= 1:\n",
        "            single_value_cols.append(col)\n",
        "    \n",
        "    if single_value_cols:\n",
        "        print(f\"⚠️ SINGLE-VALUE COLUMNS (NO VARIANCE): {single_value_cols}\")\n",
        "    else:\n",
        "        print(\"✅ No single-value columns\")\n",
        "    \n",
        "    # 6. Check for suspicious column patterns\n",
        "    suspicious_cols = []\n",
        "    for col in df.columns:\n",
        "        # Check for unnamed columns\n",
        "        if 'unnamed' in col.lower():\n",
        "            suspicious_cols.append(f\"{col} (unnamed)\")\n",
        "        # Check for index-like columns\n",
        "        if col.lower() in ['index', 'level_0', 'level_1']:\n",
        "            suspicious_cols.append(f\"{col} (index-like)\")\n",
        "    \n",
        "    if suspicious_cols:\n",
        "        print(f\"⚠️ SUSPICIOUS COLUMNS: {suspicious_cols}\")\n",
        "    else:\n",
        "        print(\"✅ No suspicious column patterns\")\n",
        "    \n",
        "    # 7. Summary statistics\n",
        "    print(f\"\\n📊 DATASET SUMMARY:\")\n",
        "    print(f\"   Shape: {df.shape}\")\n",
        "    print(f\"   Total columns: {len(df.columns)}\")\n",
        "    print(f\"   Total rows: {len(df)}\")\n",
        "    print(f\"   Duplicate rows: {df.duplicated().sum()}\")\n",
        "    print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # 8. Column types summary\n",
        "    print(f\"\\n📋 COLUMN TYPES:\")\n",
        "    print(df.dtypes.value_counts().to_dict())\n",
        "    \n",
        "    # 9. Show all column names for manual review\n",
        "    print(f\"\\n📝 ALL COLUMNS ({len(df.columns)}):\")\n",
        "    for i, col in enumerate(df.columns, 1):\n",
        "        print(f\"   {i:2d}. {col}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Run the final check on your feature engineered dataset\n",
        "final_dataset_check(merged_reduced, \"Food Price Feature Engineered\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 10\n",
        "\n",
        "## Final Data Quality Cleanup and Save\n",
        "\n",
        "When my validation check identifies problematic columns, I perform automatic cleanup to resolve these issues before saving the final dataset:\n",
        "\n",
        "### Issues I Address:\n",
        "\n",
        "1. **Duplicate Content Columns**: I remove `iso3_country` (duplicate of `iso3`) and `close_rolling_avg_3` (identical to `close`)\n",
        "2. **Empty Columns**: I remove `close_pct_change` which contains no data\n",
        "3. **Single-Value Columns**: I remove `inflation_missing` if it has no variance\n",
        "\n",
        "### My Cleanup Process:\n",
        "\n",
        "- I create a list of problematic columns to remove\n",
        "- I check if each column actually exists before attempting to remove it\n",
        "- I drop the problematic columns and create a cleaned dataset\n",
        "- I re-run the validation check to confirm all issues are resolved\n",
        "- I save the final validated dataset\n",
        "\n",
        "This ensures that my final dataset is completely clean and ready for analysis, with no duplicate or problematic columns that could cause issues in visualization or modeling.\n",
        "\n",
        "### Final Output:\n",
        "\n",
        "The result is a pristine dataset saved as `data/food_price_feature_engineered_clean.csv` that passes all data quality checks and is optimized for food price inflation analysis and visualization. This is the final, analysis-ready dataset that contains all validated features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removed 4 problematic columns\n",
            "New dataset shape: (25, 18)\n",
            "=== FINAL VALIDATION CHECK FOR FOOD PRICE FEATURE ENGINEERED - CLEANED ===\n",
            "\n",
            "✅ No duplicate column names\n",
            "✅ No columns with identical content\n",
            "✅ No completely empty columns\n",
            "✅ No columns with excessive missing values\n",
            "✅ No single-value columns\n",
            "✅ No suspicious column patterns\n",
            "\n",
            "📊 DATASET SUMMARY:\n",
            "   Shape: (25, 18)\n",
            "   Total columns: 18\n",
            "   Total rows: 25\n",
            "   Duplicate rows: 0\n",
            "   Memory usage: 0.02 MB\n",
            "\n",
            "📋 COLUMN TYPES:\n",
            "{dtype('float64'): 9, dtype('O'): 4, dtype('int32'): 2, dtype('int64'): 1, dtype('<M8[ns]'): 1, CategoricalDtype(categories=['deflation', 'low', 'medium', 'high'], ordered=True, categories_dtype=object): 1}\n",
            "\n",
            "📝 ALL COLUMNS (18):\n",
            "    1. country\n",
            "    2. iso3\n",
            "    3. components\n",
            "    4. currency\n",
            "    5. number_of_food_items\n",
            "    6. data_coverage_food\n",
            "    7. average_annualized_food_inflation\n",
            "    8. maximum_food_drawdown\n",
            "    9. average_annualized_food_volatility\n",
            "   10. date\n",
            "   11. open\n",
            "   12. high\n",
            "   13. low\n",
            "   14. close\n",
            "   15. inflation\n",
            "   16. year\n",
            "   17. month\n",
            "   18. inflation_band\n",
            "Cleaned dataset saved to: data/food_price_feature_engineered_clean.csv\n"
          ]
        }
      ],
      "source": [
        "# Clean up problematic columns in the feature engineered dataset\n",
        "\n",
        "# 1. Remove duplicate columns\n",
        "columns_to_remove = [\n",
        "    'iso3_country',  # duplicate of iso3\n",
        "    'close_pct_change',  # completely empty\n",
        "    'close_rolling_avg_3'  # identical to close\n",
        "]\n",
        "\n",
        "# 2. Check if inflation_missing has any variance before removing\n",
        "if merged_reduced['inflation_missing'].nunique() <= 1:\n",
        "    columns_to_remove.append('inflation_missing')\n",
        "\n",
        "# 3. Remove the problematic columns\n",
        "merged_cleaned = merged_reduced.drop(columns=[col for col in columns_to_remove if col in merged_reduced.columns])\n",
        "\n",
        "print(f\"Removed {len([col for col in columns_to_remove if col in merged_reduced.columns])} problematic columns\")\n",
        "print(f\"New dataset shape: {merged_cleaned.shape}\")\n",
        "\n",
        "# 4. Re-run the validation check\n",
        "final_dataset_check(merged_cleaned, \"Food Price Feature Engineered - Cleaned\")\n",
        "\n",
        "# 5. Save the truly cleaned dataset\n",
        "cleaned_path = \"data/food_price_feature_engineered_clean.csv\"\n",
        "merged_cleaned.to_csv(cleaned_path, index=False)\n",
        "print(f\"Cleaned dataset saved to: {cleaned_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion & Summary\n",
        "\n",
        "In this notebook, I have taken raw food price inflation data and transformed it into a clean, analysis-ready dataset through a series of structured ETL (Extract, Transform, Load) steps:\n",
        "\n",
        "- **Data Cleaning:** Loaded the raw CSV files, standardized column names, parsed dates, coerced numeric fields, and harmonized key categorical variables.\n",
        "- **Quality Assurance:** Checked for duplicates and missing values, ensuring the integrity of the cleaned data.\n",
        "- **Merging:** Combined country-level and item-level datasets using robust join keys, resolving duplicate key issues to prevent data inflation.\n",
        "- **Feature Engineering:** Created new variables such as time-based features, percentage changes, rolling averages, one-hot encodings, and missing value flags to enrich the dataset for analysis and modeling.\n",
        "- **Final Validation:** Performed comprehensive data quality checks and cleaned up any problematic columns\n",
        "\n",
        "This process ensures that the final dataset is tidy, consistent, and rich in features, making it suitable for exploratory data analysis, visualization, and predictive modeling. You can now confidently use `data/food_price_feature_engineered_clean.csv` for further insights and machine learning tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
